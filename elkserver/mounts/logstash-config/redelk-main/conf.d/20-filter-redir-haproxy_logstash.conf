# Part of RedELK
#
# In this file we configure the logstash filters for HAproxy logs
#
# Author: Outflank B.V. / Marc Smeets
#

filter {
  if [infra][log][type] == "redirtraffic" and [redir][program] == "haproxy" {

    # Filebeat introduces the source field for the name of the log file path. But this collides with source object from the Elastic Common Schema.
    # We have no need for the filebeat's field as its also stored in log.file.path. So we drop it.
    mutate {
      remove_field => [ "source" ]
    }

    # drop haproxy log lines about the service starting and stopping
    if "haproxy-systemd-wrapper" in [message] {
      drop { }
    }
    if "Proxy " in [message] and " started." in [message] {
      drop { }
    }
    # drop haproxy log lines when there is a config error
    if " [ALERT] " in [message] {
       drop { }
    }
    if " [ SSL] " in [message] {
       drop { }
    }
    if " [ ALL] " in [message] {
       drop { }
    }
    if " [UNIX] " in [message] {
       drop { }
    }
    if " [STAT] " in [message] {
       drop { }
    }
    if " [ TCP] " in [message] {
       drop { }
    }
    if " [WARNING] " in [message] {
       drop { }
    }
    if " [NOTICE] " in [message] {
       drop { }
    }

    # Let's first trim the syslog info from the log line
    grok {
      match => { "message" => ["%{SYSLOGTIMESTAMP:syslogtimestamp} %{NOTSPACE:[host][name]} %{PROG:[process][name]}(?:\[%{POSINT:[process][pid]}\])?: %{GREEDYDATA:messagenosyslog}"] }
    }

    mutate {
      remove_field => [ "syslogtimestamp" ]
    }

    # Sometimes HAproxy will report an SSL handshake failure, using a different log line. We check for that as well
    if "SSL handshake failure" in [message] or "TLSv1 heartbeat attack" in [message] {
      grok {
        match => { "messagenosyslog" => [ "%{IPORHOST:[source][ip]}:%{POSINT:[source][port]} \[(?<[redir][timestamp]>%{MONTHDAY}\/%{MONTH}\/%{YEAR}:%{TIME})\] (?<[redir][frontend][name]>([^/]*))%{GREEDYDATA:[http][request][body][content]}" ] }
      }
      mutate {
        add_field => { "[redir][backend][name]" => "ssl-error" }
      }
      # Set the timestamp from the log to @timestamp, example: 16/Sep/2018:07:08:21.783
      date {
        match => [ "[redir][timestamp]", "dd/MMM/yyyy:HH:mm:ss.SSS" ]
        target => "@timestamp"
        timezone => "Etc/UTC"
      }      
    } else {
      # now matching the real haproxy lines. We have several log line formats we need to match:
      # - Lines without X-Forwarded-For identified with "xforwardedfor:-"
      # - Lines with X-Forwarded-For set, identified with "xforwardedfor:$SOMEIP"
      # - any other weird sitution, i.e. cutoff lines when the log lne is larger than the redir's logbuffer size
      # Sometimes HAProxy reports lines with 'message repeated X times' in it. This is inserted into the line after the SYSLOGPROG, before "frontend. So we grok match (%{GREEDYDATA})? in each line
      #
      # We'll walk through them one by one
      #

      if "xforwardedfor:-" in [message] {
        # Lines without X-Forwarded-For identified with "xforwardedfor:-"
        grok {
          match => { "messagenosyslog" => [ "GMT:%{HTTPDATE:[redir][timestamp]} frontend:(?<[redir][frontend][name]>([^/]*))/(([^/]*))/%{IPORHOST:[redir][frontend][ip]}:%{POSINT:[redir][frontend][port]} backend:%{NOTSPACE:[redir][backend][name]} client:%{IPORHOST:[source][ip]}:%{POSINT:[source][port]} xforwardedfor:- headers:\{\|(?<[http][headers][all]>([^\}]*))} statuscode:%{INT:[http][response][status_code]} request:%{GREEDYDATA:[http][request][body][content]}" ] }
        }
      } else if "request:" in [message] {
        # Lines with X-Forwarded-For set. We already filtered out the 'xfordwardedfor:-', so anything left with a large enough log line should be good
        # Optionally match multiple Ips in xforwardedfor, eg. xforwardedfor:1.2.3.4, 2.3.4.5 -> the second IP address (or third or Nth) is an intermediate proxy such as zscaler and will be stored in source.ip_otherproxies
        grok {
          match => { "messagenosyslog" => [ "GMT:%{HTTPDATE:[redir][timestamp]} frontend:(?<[redir][frontend][name]>([^/]*))/(([^/]*))/%{IPORHOST:[redir][frontend][ip]}:%{POSINT:[redir][frontend][port]} backend:%{NOTSPACE:[redir][backend][name]} client:%{IPORHOST:[source][cdn][ip]}:%{POSINT:[source][cdn][port]} xforwardedfor:%{IPORHOST:[source][ip]}(?:(,\s)*)(?:%{GREEDYDATA:[source][ip_otherproxies]}) headers:\{\|(?<[http][headers][all]>([^\}]*))} statuscode:%{INT:[http][response][status_code]} request:%{GREEDYDATA:[http][request][body][content]}" ] }
          add_tag => [ "redirtrafficxforwardedfor" ]
        }
        # remove field [source][ip_otherproxies] if empty
        if [source][ip_otherproxies] and [source][ip_otherproxies]== "" {
          mutate {
            remove_field => [ "[source][ip_otherproxies]" ]
          }
        }
      } else {
      # catchall situation, i.e. cutoff lines when the log lne is larger than the redir's logbuffer size
        grok {
          match => { "messagenosyslog" => [ "GMT:%{HTTPDATE:[redir][timestamp]} frontend:(?<[redir][frontend][name]>([^/]*))/(([^/]*))/%{IPORHOST:[redir][frontend][ip]}:%{POSINT:[redir][frontend][port]} backend:%{NOTSPACE:[redir][backend][name]} %{GREEDYDATA:[redir][catchall]}" ] }
          add_tag => [ "redirlongmessagecatchall" ]
        }
      }

      # map header values onto dedicated fields and split the values of the headersall field into an array
      if [http][headers][all] {
        # map to dedicated fields
        grok {
          match => { "[http][headers][all]" => [ "(?<[http][headers][useragent]>([^|]*))\|(?<[http][headers][host]>([^|]*))\|(?<[http][headers][x_forwarded_for]>([^|]*))\|(?<[http][headers][x_forwarded_proto]>([^|]*))\|(?<[http][headers][x_host]>([^|]*))\|(?<[http][headers][forwarded]>([^|]*))\|(?<[http][headers][via]>([^|]*))" ] }
        }

        # split the values into an array
        mutate {
          split => { "[http][headers][all]" => "|" }
        }

        # Add useragent data
        if [http][headers][useragent] {
          useragent {
            source => "[http][headers][useragent]"
            target => "[source][host_info]"
          }
        }
      }

      # Set the timestamp from the log to @timestamp, example: 15/Apr/2018:19:22:31 +0000
      date {
        match => [ "[redir][timestamp]", "dd/MMM/yyyy:HH:mm:ss Z" ]
        target => "@timestamp"
        timezone => "Etc/UTC"
      }
    }

    if [messagenosyslog] {
      mutate {
        remove_field => [ "messagenosyslog" ]
      }
    }

    # When IPv6 is enabled on your HAProxy host, IPV4 addresses are reported like ::ffff:ipv4address. Here we cut off the ::ffff: part
    if "ffff" in [source][ip] {
      mutate {
        gsub => [
          "[source][ip]", "\:\:ffff\:", ""
        ]
      }
    }
    if "ffff" in [redir][frontend][ip] {
      mutate {
        gsub => [
          "[redir][frontend][ip]", "\:\:ffff\:", ""
        ]
      }
    }
    if "ffff" in [source][cdn][ip] {
      mutate {
        gsub => [
          "[source][cdn][ip]", "\:\:ffff\:", ""
        ]
      }
    }

    # Add data to the redirraffic.sourceip
    if [source][ip] {
      # duplicate field so we can replace it with reverse DNS lookup
      mutate {
        add_field => { "[source][domain]" => "%{[source][ip]}" }
      }
      # do reverse DNS lookup
      dns {
        reverse => ["[source][domain]"]
        action => "replace"
        timeout => "2.0"
      }
      # add geo ip info from City DB
      geoip {
        source => "[source][ip]"
        target => "tmpgeoip"
      }
      # add geo ip info from ASN DB
      geoip {
        source => "[source][ip]"
        target => "tmpgeoip"
        default_database_type => "ASN"
      }
      mutate {
        copy => {
          "[tmpgeoip][as_org]" => "[source][as][organization][name]"
          "[tmpgeoip][asn]" => "[source][as][number]"
          "[tmpgeoip][city_name]" => "[source][geo][city_name]"
          "[tmpgeoip][country_code2]" => "[source][geo][country_iso_code]"
          "[tmpgeoip][location]" => "[source][geo][location]"
          "[tmpgeoip][region_code]" => "[source][geo][region_iso_code]"
          "[tmpgeoip][region_name]" => "[source][geo][region_name]"
        }
        remove_field => [ "tmpgeoip" ]
      }
    }
    # Add data to source.cdn.ip
    if [source][cdn][ip] {
      # duplicate field so we can replace it with reverse DNS lookup
      mutate {
        add_field => { "[source][cdn][domain]" => "%{[source][cdn][ip]}" }
      }
      # do reverse DNS lookup
      dns {
        reverse => ["[source][cdn][domain]"]
        action => "replace"
        timeout => "2.0"
      }
    }
  }
}
